{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] =(12,9)\n",
    "import os\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook defines an iterator though the dataset and attempts to train alexnet to take images and map them to predictions of concatenated compressed representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, path):\n",
    "        self.path=path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(self.path+'/train-%04d.jpg'%index)\n",
    "        #img = PIL.Image.fromarray(np.stack((img,)*3,-1))\n",
    "        vect = np.load(self.path+'/train-comp-%04d.npy'%index)\n",
    "        transform = transforms.Compose([transforms.Resize((227,227)), #224? \n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                       ])\n",
    "        img = transform(img)\n",
    "        img.requires_grad=True\n",
    "        vect = torch.FloatTensor(np.concatenate(vect)) \n",
    "        return img, vect \n",
    "\n",
    "    def __len__(self):\n",
    "        return len([f for f in os.listdir(self.path) if f.endswith('.jpg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('./data/training/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self,D_out):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, D_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=500, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet(D_out=500).to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=500, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('200epochs.pt')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [] #track the losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "       device='cuda:0', grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -656.6325,  -753.9929,  -950.7822,  ...,  -610.1835,  -761.0279,\n",
       "          -926.3190],\n",
       "        [ -549.1257,  -745.2275,  -692.5160,  ...,  -678.5278,  -736.5656,\n",
       "          -740.6270],\n",
       "        [ -958.4726,  -824.1901,  -738.3862,  ...,  -986.5273, -1047.9619,\n",
       "          -983.0078],\n",
       "        ...,\n",
       "        [ -485.6332,  -913.7240,  -563.2660,  ...,  -534.1092,  -785.7769,\n",
       "          -778.3901],\n",
       "        [ -706.2590,  -594.6616,  -827.1614,  ...,  -669.1229,  -750.5424,\n",
       "          -826.1053],\n",
       "        [ -195.9621,  -381.6647,  -258.9660,  ...,  -178.0059,  -384.6135,\n",
       "          -264.9635]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.0494, -1.9980,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.0837, -2.0323,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.0837,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]],\n",
       "\n",
       "\n",
       "        [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]]]],\n",
       "       device='cuda:0', grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.0001,momentum=0.9,weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss:  nan\n",
      "epoch loss:  nan\n",
      "epoch loss:  nan\n",
      "epoch loss:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1a2300b81197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# mean loss per epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# batch iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m##########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-b08178ba04a5>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train-%04d.jpg'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#img = PIL.Image.fromarray(np.stack((img,)*3,-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train-comp-%04d.npy'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         transform = transforms.Compose([transforms.Resize((227,227)), #224? \n\u001b[1;32m     10\u001b[0m                                         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter_py3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_pathlib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 30 #size of batch\n",
    "N = 100 #number epochs\n",
    "b = int(len(train_data)/k) #number of batches\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = k, shuffle = True) #batch data loader\n",
    "\n",
    "for epoch in range(N): # epoch iterator \n",
    "    \n",
    "    running_loss = 0 # mean loss per epoch \n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader): # batch iterator \n",
    "        \n",
    "        ##########################################\n",
    "        # TRAINING\n",
    "        ##########################################\n",
    "        inputs, targets = inputs.to(device), targets.to(device) # batch to gpu\n",
    "        optimizer.zero_grad() # zero gradients\n",
    "        outputs = model(inputs) # model prediction\n",
    "        loss = criterion(outputs,targets)  # loss computation\n",
    "        loss.backward() #backpropagation\n",
    "        optimizer.step() #gradient descent \n",
    "        ##########################################\n",
    "\n",
    "        running_loss+=loss.cpu().data.item()\n",
    "\n",
    "    # print/store loss\n",
    "    # clear_output(wait=True)\n",
    "    print('epoch loss: ',round(running_loss/i,2))\n",
    "    if epoch%10==0 and epoch!=0:\n",
    "        n = epoch + 200\n",
    "        torch.save(model,'%03d-epochs.pt'%n)\n",
    "    losses.append(running_loss/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ac953d079b0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses[10:],'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. to load your previously training model:\n",
    "model.load_state_dict(torch.load('100epochs.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
