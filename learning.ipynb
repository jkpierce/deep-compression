{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] =(12,9)\n",
    "import os\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import PIL\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This notebook defines an iterator though the dataset and attempts to train alexnet to take images and map them to predictions of concatenated compressed representations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, path):\n",
    "        self.path=path\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = PIL.Image.open(self.path+'/train-%04d.jpg'%index)\n",
    "        #img = PIL.Image.fromarray(np.stack((img,)*3,-1))\n",
    "        vect = np.load(self.path+'/train-comp-%04d.npy'%index)\n",
    "        transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                       ])\n",
    "        img = transform(img)\n",
    "        img.requires_grad=True\n",
    "        vect = torch.FloatTensor(np.concatenate(vect)) \n",
    "        return img, vect \n",
    "\n",
    "    def __len__(self):\n",
    "        return len([f for f in os.listdir(self.path) if f.endswith('.jpg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('./data/training/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self,D_out):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, D_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=500, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AlexNet(D_out=500).to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 15795.198\n"
     ]
    }
   ],
   "source": [
    "k = 30 #size of batch\n",
    "N = 100 #number epochs\n",
    "b = int(len(train_data)/k) #number of batches\n",
    "losses = [] #track the losses \n",
    "\n",
    "running_loss = 0 #avg loss per epoch \n",
    "train_loader = DataLoader(train_data, batch_size = k, shuffle = True) #batch data loader\n",
    "\n",
    "for epoch in range(N): \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # batch \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # zeroed gradients \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # model prediction\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # loss\n",
    "        loss = criterion(outputs,targets)\n",
    "        running_loss+=loss \n",
    "        print('loss:', loss.cpu().data.numpy())\n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # debugging\n",
    "        #for param in model.parameters():\n",
    "        #    print(param.grad.data.sum()/len(param.grad.data))\n",
    "\n",
    "        #gradient descent \n",
    "        optimizer.step()\n",
    "\n",
    "    # print/store loss\n",
    "    print(running_loss/b)\n",
    "    losses.append(running_loss/b)\n",
    "    running_loss=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ae1148def60>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
